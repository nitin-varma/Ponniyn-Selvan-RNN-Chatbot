{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b825e3d",
   "metadata": {},
   "source": [
    "### Text Generation Using RNN trained without any pretrained embeddings and RNN trained with Word2Vec cbow embedding\n",
    "In this notebook, we will compare the performance of two models: an RNN model trained directly wthout any pretrained embeddings and another RNN model using pretrained embeddings. We will analyze the generated text using three primary metrics: **perplexity**, **diversity**, and **semantic coherence**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71d5fb86",
   "metadata": {},
   "source": [
    "### Setup\n",
    "### Import Libraries and Suppress Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de62937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from keras.models import load_model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "import absl\n",
    "\n",
    "# Suppress TensorFlow and Python warnings for cleaner output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all logs except FATAL\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328bc83",
   "metadata": {},
   "source": [
    "### Load the Necessary Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb35c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "\n",
    "# Load the necessary word-to-index and index-to-word dictionaries\n",
    "with open('pickle/word_to_index_ps.pkl', 'rb') as file:\n",
    "    word_to_index = pickle.load(file)\n",
    "\n",
    "with open('pickle/index_to_word_ps.pkl', 'rb') as file:\n",
    "    index_to_word = pickle.load(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33410ad0",
   "metadata": {},
   "source": [
    "### Function to Generate Text from a Start Prompt\n",
    "This function generates text using a given model and also collects probabilities for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2004e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Generate Text from a Start Prompt and Collect Probabilities\n",
    "def generate_sentence_with_probabilities(model, word_to_index, index_to_word, max_seq_length, start_text, senten_max_length):\n",
    "    start_text = start_text.lower()  # Convert start_text to lowercase\n",
    "    new_sentence = [word_to_index.get(word, word_to_index[unknown_token]) for word in start_text.split()]\n",
    "    probabilities = []  # List to store probabilities of chosen words\n",
    "\n",
    "    # Generate text until SENTENCE_END token or max length is reached\n",
    "    while len(new_sentence) < senten_max_length:\n",
    "        sequence = new_sentence\n",
    "        sequence_padded = pad_sequences([sequence], maxlen=max_seq_length, padding='pre')\n",
    "        predicted_probs = model.predict(sequence_padded, verbose=0)[0]\n",
    "\n",
    "        # Sample the next word index using the probabilities\n",
    "        sampled_word_index = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "        probabilities.append(predicted_probs[sampled_word_index])  # Store the probability\n",
    "\n",
    "        if sampled_word_index == word_to_index.get(sentence_end_token):\n",
    "            break\n",
    "        new_sentence.append(sampled_word_index)\n",
    "\n",
    "    # Convert indices back to words\n",
    "    sentence_str = [index_to_word[idx] for idx in new_sentence]\n",
    "    generated_text = ' '.join(sentence_str)\n",
    "    generated_text = generated_text.replace('_ comma _', ',').replace('_ eol _', '.\\n') + '.'\n",
    "    return generated_text, probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93e4a138",
   "metadata": {},
   "source": [
    "### Load both the models and generate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125067ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sentences Generated by RNN Model without any pretrained embedding===\n",
      "\n",
      "Generated text - 0: குந்தவை தேவி பார்த்துக் கொண்டிருப்பது போல மக்கள் அந்தக் உரமும் உள்ள இரண்டு பேர் என்னைத் தோள் கொடுத்துத் தூக்கிக் கொள்ளுங்கள் நகர்ந்து வந்து ஒரு சத்தம் வந்து நிற்பதைக் கண்டு சிந்தனையில் தாதியரின் முகங்களும் உடனே போகிறான் ராணிக்கு பயங்கரமாக விட்டேன்.\n",
      "Generated text - 1: குந்தவை தேவி வானதியைப் தான் பார்த்து அது பல்லக்கில் இருந்தது என்பதை முன்னமே நான் ஒரு நாளும் சொல்ல மாட்டேன் தாங்கள் வெளியில் செல்ல இளவரசிகள் இருவரும் ஆதுர சென்று சாலையில் சோழப் பேரரசில் பெருந்தரத்து அரசாங்க அதிகாரிகளாகவும் பதவி வகித்து வந்தார்கள் என்பது தவறி விழுந்து முழுகி இறந்து விட்டார் என்று சொன்னாய்.\n",
      "Generated text - 2: குந்தவை தேவி என்னிடம் கூறியது முடியாத போது யார் என்பது மதுராந்தகர்.\n",
      "Generated text - 3: குந்தவை தேவி அவருடைய முகத்தையே பார்த்துக் கொண்டு வந்தியத்தேவனும் சிறிது தூரம் சென்று கொண்டிருந்தார்கள் என்று பார்த்துக் கொள்ளுங்கள் சண்டை எதற்கு.\n",
      "Generated text - 4: குந்தவை தேவி இலங்கைக்குப் போகிறேன் என்று சொல்லிக் கொண்டூ படகு வெள்ளத்தின் வேகத்தினால் மரத்தடியில் நிற்க முடியாமல் நகர்ந்து அவள் விம்மி விம்மி விம்மி அழுது கொண்டே எழுந்திருப்பாள் என்பதிலும் ஐயமில்லை என்பது பழுவூர் ராணி என்பதை வானதி முன்னணியில் நின்று பராக்கிரமச் செயல்கள் புரிந்தார் “வீரபாண்டியன் “வீரபாண்டியன் குற்றம் தரும் விஷயத்தைச் சொல்லிக் கொண்டிருந்தாள் என்பது நிகழ்ச்சிகள் அபாயங்கள் பல கண்டங்கள் ஏற்படும் என்றா துரோகம் செய்தால் எனக்கும்.\n",
      "Generated text - 5: குந்தவை தேவி திரும்பி வானதியைப் பார்த்து எழுந்து கணமும் எனக்கு ஒரு சந்தேகம் நினைவு வந்து விடலாமா என்று கோட்டைத் தளபதி தமக்குள்ளே சொல்லிக் கொண்டார் என்றும் அதனால் விளைந்த சிரிப்பையும் பழுவூர் மன்னர் பொறுத்தருள வேண்டூம் என்று உணர்ந்திருந்த அந்தக் கிழச் சிங்கத்தின் கர்ஜனை அவரைப் என்று நேராமல் சொல்வதைக் காட்டூக்குள் புகுந்து நாட்டில் பாண்டியர் சைன்யத்தில் அணியும் நவரத்தின மாலை ஒன்றை வைத்துப் போட்டு விட்டுப் பூஜை.\n",
      "Generated text - 6: குந்தவை தேவி தான் வெளியிலே போய் விட வேண்டும் என்று ஆசை கூறினார் சுந்தர சோழ உருவாகி வரவில்லை.\n",
      "Generated text - 7: குந்தவை தேவி பழையாறைக்குப் போகவும் ஆட்கள் இன்னும் இரண்டு பேரும் சேர்ந்து சொல்லுவது ஒன்றும் விளங்கவில்லை ஆன பிறகு வந்தியத்தேவன் ஓரிடத்தில் ஒரு பெருங்கூட்டம் நின்று கொண்டிருப்பதையும் அந்தக் கூட்டத்துக்குள்ளேயிருந்து யாரோ சிலர் உரத்த குரலில் வாக்குவாதம் செய்யும் சத்தம் வருவதையும் கவனித்தான்.\n",
      "Generated text - 8: குந்தவை தேவி இச்சமயம் நான் மறைந்து போய் விட்டால் என்ன செய்கிறது என்பது வானதியின் கண்களில் நீர் அருவி விழும் இடத்தை நெருங்கி வந்து கொண்டிருப்பதைப் பார்த்தேன் எனக்குக் குதிரை அணிந்து அவனும் போக ஆசைப்படூவதாகத் தோன்றுகிறது.\n",
      "Generated text - 9: குந்தவை தேவி என்று தெரிந்து கொண்டுதான் அவ்விதம் கேட்கிறானோ என்று முகத்திலிருந்து அறிய முடியாதபடி அறிய பார்த்ததும் கேட்டூச் வேண்டூம் என்று பூங்குழலி சுற்று முற்றும் உற்றுப் பார்த்துக் கொண்டே அங்குமிங்கும் சென்று வந்தியத்தேவன் சிறிது நேரம் சிந்தனை செய்து கொண்டிருந்த பிறகு வானதி வெகு தூரம் சென்று வீர நாராயண ஏரியில் விழுந்து அதை ஒரு பொங்கும் கடலாக ஆக்கியிருந்தது.\n",
      "Generated text - 10: குந்தவை தேவி தான் அங்கு வெற்றி பெற்று அதற்குள் பழுவேட்டரையர் அவருடைய கரங்களை தந்தையின் மோதிரத்தைக் செயலைப் குறித்து அடிக்கடி அவர் காதில் ஒலித்துக் கொண்டே இருந்தது.\n"
     ]
    }
   ],
   "source": [
    "# Load and generate text using RNN model\n",
    "get_custom_objects().update({'BatchNormalization': BatchNormalization})\n",
    "rnn_model = load_model('model/rnn_direct_model.h5', custom_objects={'BatchNormalization': BatchNormalization})\n",
    "\n",
    "# Generate text using RNN model\n",
    "rnn_sentences = []\n",
    "rnn_probabilities = []\n",
    "\n",
    "print(\"=== Sentences Generated by RNN Model without any pretrained embedding===\\n\")\n",
    "for i in range(11):\n",
    "    start_prompt = \"குந்தவை தேவி\"\n",
    "    generated_output, probs = generate_sentence_with_probabilities(\n",
    "        rnn_model, word_to_index, index_to_word, 75, start_prompt, senten_max_length=50\n",
    "    )\n",
    "    rnn_sentences.append(generated_output)\n",
    "    rnn_probabilities.extend(probs)\n",
    "    print(f\"Generated text - {i}:\", generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d27ac97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sentences Generated by RNN Model with Word2Vec CBOW pretrained embeddings===\n",
      "\n",
      "Generated text - 0: குந்தவை தேவி முதலியோர் வந்தியத்தேவனைப் பார்த்து விட்டு வருவதாகச் சொல்லிவிட்டு விடு என்று சொல்ல வேண்டும் என்ற ஆசை தானே ஆசை கொண்டு சின்னப் பழுவேட்டரையரின் மனதில் கொஞ்ச தூரம் வல்லவரையனுக்கு காதில் ஒன்று விழுந்து வேளக்காரப் படையில் ஓர் எண்ணத்தை அங்கே வந்தியத்தேவன் அங்கே வந்து மணம் புரிந்த மருமகர் திடீரென்று அவன் பின் அபிமானம் இருந்தது என்று எனக்குப் அவள் மனத்தில் தெரிந்து கொண்டூ தான் அங்கே.\n",
      "Generated text - 1: குந்தவை தேவி கரையை கீழே கிடந்த மீது கால் ஒரு கை பார்க்க வேண்டும் என்று வானத்தைப் ஆட்சி தெரிந்து கொள்வது பின்னர் அந்த மகா மன்னர் பரம்பரையில் வந்து சில தூரத்தில் பகைவர்கள் வந்தவர்கள் அல்லவா பொன் கோயில் எடுக்க வேண்டும் என்றும் சொல்லி விட்ட மனம் நிம்மதி வந்தியத்தேவனுடைய மனதில் ஏரி ஏரி என்று பெயர் மாறுதல் யோசித்துக் கொண்டிருந்தார்கள் என்று முடிவு செய்து கொண்டிருந்தபோது மனம்.\n",
      "Generated text - 2: குந்தவை தேவி அனுப்பி விட்டூ மறு மீது யாரும் குற்றம் திருப்தி செய்ய வேண்டும்” என்றார் குந்தவை தேவியைப் முதன் நம் முன்னோர்கள் கடைப்பிடித்து வந்திருப்பதென்ன என்னும் வாணர் குலத்து உயிர் வந்து அவரைக் காரியம் செய்ய வேண்டிய காரியம் உண்டு என்று என் காதில் நின்றேன் நமது பேச்சு அவன் காதில் நன்றாக விழவில்லை வேண்டிய காரியம் இருந்தாலும் என்னும் பூர்வ நான் தொடர்ந்து தஞ்சைக்கு வந்து தங்களைக்.\n",
      "Generated text - 3: குந்தவை தேவி வந்த செய்தி எழுதி கொண்டு இராமேசுவரத்துக்குப் சேவையில் சில கரையில் ஓர் அடி முன்னால் வந்து மற்ற வீரர்கள் விரைந்து போய்ப் படகில் போட்டுக் கொண்டு என்று ஊகித்துக் கொண்டு சிறிது நேரம் முடிவு செய்து கொண்டூ மேல் கிளைக்குப் பாய்கிறது என்று சபதம் என்று முடிவு செய்து ஆனந்தமாய்க் போக வைத்து இரு ஒரு நொடியில் செய்து கீழே குதித்தான் யானை மீது பிரயாணம் பிரயாணம்.\n",
      "Generated text - 4: குந்தவை தேவி செய்கிறான் பார்த்தால் அவள் முகம் எனக்குத் தெரிந்த சத்தம் இருக்கிறதா அல்லவா.\n",
      "Generated text - 5: குந்தவை தேவி பலி ததும்பிய கண்களினால் ஒரு பக்கத்தில் கிடந்து போல் அதன் களைப்புத் விழுந்து நின்று அவனுடைய கண்கள் நோக்கிப் கிடந்த வைஷ்ணவ அமர்ந்திருந்த வீதியில் வந்தியத்தேவனுடைய தலையைக் வரையில் வீற்றிருந்த பின்னர் அரச பக்கத்தில் அங்கே போய் நின்று கீழே உற்றுப் பார்த்துக் கொண்டு அங்கே விரைந்து விரைந்து போய் நின்று சப்தம் அவர்களுடைய கையில் எடுத்துக் கொண்டு மேலே தூண் மறைவில் நின்று கீழே திரும்ப.\n",
      "Generated text - 6: குந்தவை தேவி முதலில் தப்பிச் போகிறது பேறு என்று தெரிந்து கொண்ட ஆழ்வார்க்கடியார் என்ன செய்தி சொல்லிக் கொண்டு ஆழ்வார்க்கடியான் ஒரு நீண்ட பெருமூச்சு கொண்ட விட்டு அவளை ஒரு கணம் உற்றுப் பார்த்துக் கொண்டிருந்த பூங்குழலி அவள் காதில் விழுந்து அவருக்குச் வேண்டும் என்றும் தீர்மானித்துக் கொண்டூ கொண்டூ திருக்கோவலூர் மலையமானும் பழுவேட்டரையர் உண்மையான வந்தியத்தேவனுடைய மனதில் நன்கு இழந்து பாய்ந்து நிற்பது கீழே விட்டதோ என்னும் மனம்.\n",
      "Generated text - 7: குந்தவை தேவி இந்தக் கதவு அங்கே வரையில் என் உடம்பு கொஞ்சம் வெகு காலம் அரசு புரிந்தவர் வரையில் யாருக்கும் ஒரு பக்கத்தில் கிடந்து செய்து கொண்டு போய் விட்டூ விட்டுப் பழுவேட்டரையரின் இதுவரை மட்டூம் ஒப்புக் விட்டுப் பிரிந்து உள்ளே போக எங்கேயோ தூரத்தில் அடைந்து விடவில்லை கீழே விழுந்து வெள்ளத்தில் நதி ஒரு சிறு பெண்ணும் நாம் இன்னும் மறந்து இவர்கள் கையில் உள்ள சபதம் இல்லாமல்.\n",
      "Generated text - 8: குந்தவை தேவி அருகில் போய்ச் எரிந்து கொண்டூ ஓடி வந்து அவரைக் அப்புறம் கவலைப்படவில்லை தன்னுடைய கடமை தீர்ந்தது என்று தெரிந்து கொண்டூ முடிவு செய்து விட்டார்கள் என்று முன்னால் மலையமான் வரும்படி சொல்லி அனுப்ப எடுத்துக் பக்கத்தில் கிடந்து பார்க்காமல் முன் முடிவு செய்து விட்டுப் போய் விட்டீர்கள் என்று கண்டுபிடிக்க வந்தியத்தேவன் ஆற்றங்கரை ஓரத்தை உற்றுப் பார்த்துக் கொண்டே மெதுவாகச் வந்தியத்தேவன் குந்தவை கேட்டு சேந்தன் அமுதன்.\n",
      "Generated text - 9: குந்தவை தேவி என் சகோதரன் பாத்தியதை அறிந்த செய்தி சொல்ல முடியாத விகாரத்தை முயற்சி சும்மா ஏன் பேச வேண்டும் என்று ஆசை உனக்கு ஆவல் வந்தியத்தேவனுக்கு நினைவு வந்தியத்தேவனுடைய கண்கள் மக்கள் ஊகித்துக் கொண்டிருந்த இளம் வீரனைத் திக்குமுக்காடித் திணறச் சிந்திக்கத் எவ்வளவு பீதி சிறிது நேரம் கொண்டிருந்த காட்சி அவருடைய மனத்தை உருக்கியது “அக்கா தேவியின் முகம் மறுபடி முன்னைக் காட்டிலும் அதிகமாக வாடியது தான் அது.\n",
      "Generated text - 10: குந்தவை தேவி பழுவேட்டரையர் ஓலையை கொண்டூ மீது பெரிய பழுவேட்டரையர் மீதும் இத்தனை நேரமும் அனுப்பி செல்வாக்கு என்பதை மறந்து ஒப்புக் கொண்டூ காஞ்சிக்குப் ஆச்சரியப்பட்டுப் ஆச்சரியப்பட்டுப் போக முடியாது என்று சொல்லி விட்டுப் போக வேண்டும் என்று வந்தியத்தேவனுடைய உள்ளம் மூழ்கி அன்பும் நடக்கும் ஒன்று இருந்தால் நான் எவ்வளவோ தீங்கு செய்தால் கோரமான கேட்டு வந்தியத்தேவன் செவிகளில் கூறியது சிறிது ஈனஸ்வரத்தில் கேட்டது வந்தியத்தேவன் கூர்ந்து எடுத்து.\n"
     ]
    }
   ],
   "source": [
    "# Load and generate text using RNN CBOW model\n",
    "cbow_model = load_model('model/rnn_cbow_model.h5', custom_objects={'BatchNormalization': BatchNormalization})\n",
    "\n",
    "# Generate text using CBOW model\n",
    "cbow_sentences = []\n",
    "cbow_probabilities = []\n",
    "\n",
    "print(\"\\n=== Sentences Generated by RNN Model with Word2Vec CBOW pretrained embeddings===\\n\")\n",
    "for i in range(11):\n",
    "    start_prompt = \"குந்தவை தேவி\"\n",
    "    generated_output, probs = generate_sentence_with_probabilities(\n",
    "        cbow_model, word_to_index, index_to_word, 75, start_prompt, senten_max_length=50\n",
    "    )\n",
    "    cbow_sentences.append(generated_output)\n",
    "    cbow_probabilities.extend(probs)\n",
    "    print(f\"Generated text - {i}:\", generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9c86da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sentences Generated by DNN Model without any pretrained embedding===\n",
      "\n",
      "Generated text - 0: குந்தவை தேவி ஏமாற்றி நிறுத்தி பார்த்த காரியத்தை அவர் உன்னைத் திரும்பிப் பார்த்து சொல்லிக் கொண்டிருந்தான் போதும் என்பதை தெரிந்து கொள்ள குந்தவை , பூர்வீக நதியில் ஒரு கதை கீழே மதி , எவ்வளவு கதை UNKNOWN_TOKEN , அந்த மிருகங்களையெல்லாம் பிடித்துக் UNKNOWN_TOKEN , சொர்க்கத்திலிருந்து UNKNOWN_TOKEN UNKNOWN_TOKEN UNKNOWN_TOKEN இல்லை.\n",
      "Generated text - 1: குந்தவை தேவி தாங்களும் தப்பித்துக் கொண்டு போகும் போது சேவை UNKNOWN_TOKEN UNKNOWN_TOKEN UNKNOWN_TOKEN UNKNOWN_TOKEN குறுக்கு வழியில் UNKNOWN_TOKEN கை UNKNOWN_TOKEN UNKNOWN_TOKEN அதனால்.\n",
      "Generated text - 2: குந்தவை தேவி அவனிடம் என்னைப் பிரிந்து வந்து ஓரிடத்தில் வந்து , பழுவேட்டரையர் பெயரால் மாறாக வந்தியத்தேவன் நடந்த நீ என்ன எதிர்ப்பட்டால் UNKNOWN_TOKEN கொள்ள வேண்டும்.\n",
      "Generated text - 3: குந்தவை தேவி இங்கே வந்தியத்தேவனும் சுரங்கப் பாதையில் அதன் பல்லக்கு தரையில் விழாமல் மோதிக் கொண்டு ஒரு விஷயம் என்பதையும் தெரிந்துகொள்ள.\n",
      "Generated text - 4: குந்தவை தேவி வந்திருக்கிறீர்கள் என்று வியப்புடன் நன்கு அப்புறம் அவனுக்கு ஒரு நொடியில் உய்விக்க மாட்டேன் என்று கேட்க வேண்டும்.\n",
      "Generated text - 5: குந்தவை தேவி உடனே முன்னால் போய்ச் பரந்த கண்களினால் சில மீது ஏறி வந்து நிற்பது என்றும் சொல்லி மூர்ச்சை சுமந்து கைக்கு கொள்ள கேட்டுக் கொண்டான்.\n",
      "Generated text - 6: குந்தவை தேவி இங்கே அவனை நான் அவளைக் கவர்ந்து கொண்டூ வந்தவர்கள் தன் மண்டபத்துக்குள் UNKNOWN_TOKEN சொல்லு.\n",
      "Generated text - 7: குந்தவை தேவி நிம்மதியாகப் வந்ததற்கு மாறாக அவனுடைய பயங்கர உன்னைக் மீசையைத் எல்லாருடைய பண்டாரமும் ஒருவேளை நடந்தது செய்து கொள்கிறான் , கொண்டது , அந்தப் கைவரிசையைக் UNKNOWN_TOKEN.\n",
      "Generated text - 8: குந்தவை தேவி வரச் செய்யப் போகிறேன் கொஞ்சம் சொல்லி கொண்டூ அந்தத் ஊர்வலம் வருவது பற்றிக் போகிறது என்று தான் தான் , என்னும் ஆசை இது UNKNOWN_TOKEN என்று கல்வெட்டுச் அறுசுவைச் கொண்டு சிறிது.\n",
      "Generated text - 9: குந்தவை தேவி போய் என் மூளையை விரட்டிக் கண்டுபிடிக்க முயன்ற ஜங்கார தாபம் இருக்கிறது.\n",
      "Generated text - 10: குந்தவை தேவி எழுந்து விரைந்து மீது வந்து வெளிச்சம் தவறி அடித்துக் கொண்டூ உள்ளே கீழே நின்றார்கள்.\n"
     ]
    }
   ],
   "source": [
    "# Load and generate text using RNN CBOW model\n",
    "dnn_model = load_model('model/dnn_model.h5')\n",
    "# Generate text using CBOW model\n",
    "dnn_sentences = []\n",
    "dnn_probabilities = []\n",
    "\n",
    "print(\"\\n=== Sentences Generated by DNN Model without any pretrained embedding===\\n\")\n",
    "for i in range(11):\n",
    "    start_prompt = \"குந்தவை தேவி\"\n",
    "    generated_output, probs = generate_sentence_with_probabilities(\n",
    "        dnn_model, word_to_index, index_to_word, 75, start_prompt, senten_max_length=50\n",
    "    )\n",
    "    dnn_sentences.append(generated_output)\n",
    "    dnn_probabilities.extend(probs)\n",
    "    print(f\"Generated text - {i}:\", generated_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e34aaae2",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "Perplexity measures how well a probability model predicts a sample. Lower values indicate better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecab7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN-direct embedding Model Perplexity: 3.97\n",
      "RNN-cbow embedding Model Perplexity: 13.47\n",
      "DNN-direct embedding Model Perplexity: 25.08\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Perplexity\n",
    "def calculate_perplexity(probabilities):\n",
    "    return np.exp(-np.mean(np.log(probabilities))) if probabilities else float('inf')\n",
    "\n",
    "# Calculate perplexity for both models\n",
    "rnn_perplexity = calculate_perplexity(rnn_probabilities)\n",
    "cbow_perplexity = calculate_perplexity(cbow_probabilities)\n",
    "dnn_perplexity = calculate_perplexity(dnn_probabilities)\n",
    "print(f\"RNN-direct embedding Model Perplexity: {rnn_perplexity:.2f}\")\n",
    "print(f\"RNN-cbow embedding Model Perplexity: {cbow_perplexity:.2f}\")\n",
    "print(f\"DNN-direct embedding Model Perplexity: {dnn_perplexity:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30953c4a",
   "metadata": {},
   "source": [
    "### Diversity\n",
    "Diversity measures the uniqueness of words used in the generated text. Higher values indicate more diverse vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d45958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN-direct embedding Model Diversity: 0.77\n",
      "RNN-cbow embedding Model Diversity: 0.64\n",
      "DNN-direct embedding Model Diversity: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Diversity\n",
    "def calculate_diversity(sentences):\n",
    "    unique_words = set()\n",
    "    total_words = 0\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        unique_words.update(words)\n",
    "        total_words += len(words)\n",
    "    return len(unique_words) / total_words if total_words > 0 else 0\n",
    "\n",
    "# Calculate diversity for both models\n",
    "rnn_diversity = calculate_diversity(rnn_sentences)\n",
    "cbow_diversity = calculate_diversity(cbow_sentences)\n",
    "dnn_diversity = calculate_diversity(dnn_sentences)\n",
    "print(f\"RNN-direct embedding Model Diversity: {rnn_diversity:.2f}\")\n",
    "print(f\"RNN-cbow embedding Model Diversity: {cbow_diversity:.2f}\")\n",
    "print(f\"DNN-direct embedding Model Diversity: {dnn_diversity:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1b15bcd",
   "metadata": {},
   "source": [
    "### Semantic Coherence\n",
    "Semantic coherence measures how well the words in a sentence relate to each other. Higher values indicate better coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed5d958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN-direct embedding Model Semantic Coherence: 0.27\n",
      "RNN-cbow embedding Model Semantic Coherence: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Semantic Coherence\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to calculate Semantic Coherence\n",
    "def calculate_semantic_coherence(sentences, model, word_to_index):\n",
    "    embedding_layer = model.get_layer('embedding_layer')\n",
    "    embedding_weights = embedding_layer.get_weights()[0]\n",
    "\n",
    "    sentence_vectors = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        vectors = [embedding_weights[word_to_index[word]] for word in words if word in word_to_index]\n",
    "        if vectors:\n",
    "            sentence_vector = np.mean(vectors, axis=0)\n",
    "            sentence_vectors.append(sentence_vector)\n",
    "\n",
    "    sentence_vectors = np.array(sentence_vectors)\n",
    "    pairwise_similarities = cosine_similarity(sentence_vectors)\n",
    "    avg_similarity = np.mean(pairwise_similarities)\n",
    "    return avg_similarity\n",
    "\n",
    "# Calculate semantic coherence for both models\n",
    "rnn_coherence = calculate_semantic_coherence(rnn_sentences, rnn_model, word_to_index)\n",
    "cbow_coherence = calculate_semantic_coherence(cbow_sentences, cbow_model, word_to_index)\n",
    "print(f\"RNN-direct embedding Model Semantic Coherence: {rnn_coherence:.2f}\")\n",
    "print(f\"RNN-cbow embedding Model Semantic Coherence: {cbow_coherence:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23073144",
   "metadata": {},
   "source": [
    "## Final Results and Conclusion\n",
    "\n",
    "1. **`Perplexity`**: The RNN model without pre-trained embeddings achieved a lower perplexity (3.97) compared to the CBOW-embedding RNN model (13.47), with the DNN model scoring the highest perplexity at 25.08. This indicates that the direct RNN model is more effective at predicting sequences within this dataset, making it better suited for generating text with more accurate predictions in this specific context.\n",
    "\n",
    "2. **`Diversity`**: The RNN model without pre-trained embeddings demonstrated the highest diversity (0.77), closely followed by the direct DNN model (0.70) and the CBOW model (0.64). This shows that both RNN and DNN models generated a more varied vocabulary. The direct RNN model shows a strong ability to produce diverse language while maintaining contextual relevance, out of all.\n",
    "\n",
    "3. **`Semantic Coherence`**: As expected, the RNN model with CBOW embeddings outperformed in terms of semantic coherence, achieving a higher average coherence score (0.50) compared to the direct RNN model (0.27). This aligns with the purpose of using CBOW embeddings, which are designed to capture meaningful relationships between words and boost coherence in generated text. The DNN model was not evaluated for semantic coherence, as it lacks the architecture to capture semantic relationships effectively, and high training loss further limited its ability to produce semantically structured sentences.\n",
    "\n",
    "`Based on these metrics`:\n",
    "- For **accurate predictions and vocabulary diversity**, the RNN model trained without pre-trained embeddings is a strong choice, with low perplexity and high diversity, making it suitable for scenarios where variety and predictive accuracy are prioritized.\n",
    "- For **better semantic coherence**, the RNN model with CBOW embeddings is preferred, as it benefits from pre-trained embeddings that enhance cohesion in generated text.\n",
    "\n",
    "### Final Recommendation\n",
    "While pre-trained embeddings typically enhance semantic coherence, in this case, the **RNN model without pre-trained embeddings is preferable**. It provides high predictive accuracy, meaningful diversity, and an overall coherent style that aligns closely with the Ponniyin Selvan narrative. However, if semantic coherence is prioritized, the CBOW model remains a valuable alternative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
